{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5820e48",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 1. SETUP & IMPORTS\n",
    "# ==========================================\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import cv2\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import subprocess\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# ==========================================\n",
    "# 2. AUTHENTICATION & DATA VERIFICATION\n",
    "# ==========================================\n",
    "# We only auth if we actually need to download something.\n",
    "KEY_FILE = 'colab-upload-bot-key.json'\n",
    "\n",
    "# --- PATHS (Relative for Workbench) ---\n",
    "LOCAL_BASE_DIR = './data_local'\n",
    "LOCAL_TRAIN_DIR = os.path.join(LOCAL_BASE_DIR, 'trainsm')\n",
    "LOCAL_JSON_PATH = './train.json'\n",
    "OUTPUT_CSV_PATH = './metrics/strat_1_cpu.csv'\n",
    "\n",
    "# GCS Config (Only used if local data is missing)\n",
    "BUCKET_NAME = 'vis-data-2025'\n",
    "GCS_TRAIN_DIR = f'gs://{BUCKET_NAME}/trainsm'\n",
    "GCS_JSON_URL = f'gs://{BUCKET_NAME}/train.json'\n",
    "\n",
    "print(f\"\\nüöÄ CHECKING DATA...\")\n",
    "\n",
    "# A. Check Annotations\n",
    "if not os.path.exists(LOCAL_JSON_PATH):\n",
    "    print(f\"‚¨áÔ∏è 'train.json' not found. Downloading...\")\n",
    "    if os.path.exists(KEY_FILE):\n",
    "        os.system(f'gcloud auth activate-service-account --key-file=\"{KEY_FILE}\"')\n",
    "    os.system(f'gsutil cp {GCS_JSON_URL} {LOCAL_JSON_PATH}')\n",
    "else:\n",
    "    print(\"‚úÖ Annotations found locally.\")\n",
    "\n",
    "# B. Check Video Data\n",
    "if os.path.exists(LOCAL_TRAIN_DIR) and len(os.listdir(LOCAL_TRAIN_DIR)) > 0:\n",
    "    print(f\"‚úÖ Training data found in '{LOCAL_TRAIN_DIR}'. Skipping download.\")\n",
    "else:\n",
    "    print(f\"‚¨áÔ∏è Data not found. Downloading from GCS...\")\n",
    "    if os.path.exists(KEY_FILE):\n",
    "        os.system(f'gcloud auth activate-service-account --key-file=\"{KEY_FILE}\"')\n",
    "    \n",
    "    os.makedirs(LOCAL_BASE_DIR, exist_ok=True)\n",
    "    # Download with progress bar logic (Simplified for brevity)\n",
    "    os.system(f'gsutil -m cp -r {GCS_TRAIN_DIR} {LOCAL_BASE_DIR}')\n",
    "\n",
    "# ==========================================\n",
    "# 3. MOTION COMPENSATION LOGIC (CPU)\n",
    "# ==========================================\n",
    "def align_frames(prev_gray, curr_gray):\n",
    "    \"\"\"\n",
    "    Calculates camera motion and warps prev_gray to match curr_gray.\n",
    "    \"\"\"\n",
    "    # 1. Detect Features (Shi-Tomasi Corners)\n",
    "    # We limit to 200 points to keep CPU speed high\n",
    "    prev_pts = cv2.goodFeaturesToTrack(prev_gray, maxCorners=200, qualityLevel=0.01, minDistance=30)\n",
    "\n",
    "    if prev_pts is None: \n",
    "        return None # Cannot align\n",
    "\n",
    "    # 2. Optical Flow (Lucas-Kanade) - Track points to current frame\n",
    "    curr_pts, status, err = cv2.calcOpticalFlowPyrLK(prev_gray, curr_gray, prev_pts, None)\n",
    "\n",
    "    # Filter valid points\n",
    "    good_prev = prev_pts[status == 1]\n",
    "    good_curr = curr_pts[status == 1]\n",
    "\n",
    "    if len(good_prev) < 4: \n",
    "        return None # Need 4 points to calculate Homography\n",
    "\n",
    "    # 3. Find Homography (Transformation Matrix)\n",
    "    # RANSAC filters out outliers (like the moving bird itself!)\n",
    "    H, mask = cv2.findHomography(good_prev, good_curr, cv2.RANSAC, 5.0)\n",
    "\n",
    "    if H is None:\n",
    "        return None\n",
    "\n",
    "    # 4. Warp Previous Frame to match Current Frame\n",
    "    height, width = prev_gray.shape\n",
    "    warped_prev = cv2.warpPerspective(prev_gray, H, (width, height))\n",
    "\n",
    "    return warped_prev\n",
    "\n",
    "# ==========================================\n",
    "# 4. HELPER FUNCTIONS\n",
    "# ==========================================\n",
    "def load_json_ground_truth(json_path):\n",
    "    if not os.path.exists(json_path): return {}\n",
    "    with open(json_path, 'r') as f: data = json.load(f)\n",
    "    \n",
    "    id_to_filename = {img['id']: img['file_name'] for img in data['images']}\n",
    "    img_id_to_boxes = defaultdict(list)\n",
    "    if 'annotations' in data:\n",
    "        for ann in data['annotations']:\n",
    "            img_id_to_boxes[ann['image_id']].append(ann['bbox'])\n",
    "\n",
    "    filename_to_gt = {}\n",
    "    for img_id, filename in id_to_filename.items():\n",
    "        key = filename\n",
    "        if key.startswith('train/'):\n",
    "            key = key.replace('train/', '', 1)\n",
    "        filename_to_gt[key] = img_id_to_boxes.get(img_id, [])\n",
    "    \n",
    "    return filename_to_gt\n",
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    x1, y1, w1, h1 = box1\n",
    "    x2, y2, w2, h2 = box2\n",
    "    xi1, yi1 = max(x1, x2), max(y1, y2)\n",
    "    xi2, yi2 = min(x1 + w1, x2 + w2), min(y1 + h1, y2 + h2)\n",
    "    inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)\n",
    "    union_area = (w1 * h1) + (w2 * h2) - inter_area\n",
    "    return inter_area / union_area if union_area > 0 else 0\n",
    "\n",
    "def get_next_version_path(path):\n",
    "    \"\"\"\n",
    "    Returns a new file path with an incremented version number if the file already exists.\n",
    "    Example: 'data.csv' -> 'data_1.csv' -> 'data_2.csv'\n",
    "    \"\"\"\n",
    "    # If the file doesn't exist yet, simply return the original path\n",
    "    if not os.path.exists(path):\n",
    "        return path\n",
    "\n",
    "    directory, filename = os.path.split(path)\n",
    "    name, ext = os.path.splitext(filename)\n",
    "    \n",
    "    # Create the directory if it doesn't exist (safety check)\n",
    "    if directory and not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    # Regex pattern to match files like \"baseline_gpu_123.csv\"\n",
    "    # Matches: exact_name + underscore + digits + exact_extension\n",
    "    pattern = re.compile(rf\"^{re.escape(name)}_(\\d+){re.escape(ext)}$\")\n",
    "    \n",
    "    max_version = 0\n",
    "    \n",
    "    # List files in the directory to find the highest existing number\n",
    "    for f in os.listdir(directory if directory else '.'):\n",
    "        match = pattern.match(f)\n",
    "        if match:\n",
    "            version = int(match.group(1))\n",
    "            if version > max_version:\n",
    "                max_version = version\n",
    "\n",
    "    # Next version is max found + 1\n",
    "    new_filename = f\"{name}_{max_version + 1}{ext}\"\n",
    "    return os.path.join(directory, new_filename)\n",
    "\n",
    "# ==========================================\n",
    "# 5. MAIN PIPELINE\n",
    "# ==========================================\n",
    "def run_gmc_evaluation():\n",
    "    gt_data = load_json_ground_truth(LOCAL_JSON_PATH)\n",
    "    if not gt_data: \n",
    "        print(\"‚ùå Annotations not loaded.\")\n",
    "        return\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    # Find videos in ./data_local/trainsm/\n",
    "    video_folders = sorted(glob.glob(os.path.join(LOCAL_TRAIN_DIR, '*')))\n",
    "    video_folders = [f for f in video_folders if os.path.isdir(f)]\n",
    "\n",
    "    if not video_folders:\n",
    "        print(f\"‚ùå No video folders found in {LOCAL_TRAIN_DIR}.\")\n",
    "        return\n",
    "\n",
    "    print(f\"üìÇ Found {len(video_folders)} videos. Starting GMC (CPU)...\")\n",
    "    print(f\"\\n{'Video':<10} | {'Frames':<6} | {'FPS':<6} | {'Prec':<6} | {'Recall':<6} | {'F1':<6}\")\n",
    "    print(\"-\" * 65)\n",
    "\n",
    "    total_tp = total_fp = total_fn = total_time = total_frames = 0\n",
    "    results_data = []\n",
    "\n",
    "    for video_path in video_folders:\n",
    "        video_name = os.path.basename(video_path)\n",
    "        images = sorted(glob.glob(os.path.join(video_path, '*.jpg')))\n",
    "        if not images: continue\n",
    "\n",
    "        vid_tp = vid_fp = vid_fn = 0\n",
    "        vid_start = time.time()\n",
    "        n_frames = len(images)\n",
    "        \n",
    "        # Initialize Previous Frame\n",
    "        prev_gray = None\n",
    "\n",
    "        for i, img_path in enumerate(images):\n",
    "            # Print progress cleanly\n",
    "            if i % 50 == 0:\n",
    "                percent = ((i + 1) / n_frames) * 100\n",
    "                sys.stdout.write(f\"\\rüëâ Processing [{video_name}] Frame {i+1}/{n_frames} ({percent:.1f}%)\")\n",
    "                sys.stdout.flush()\n",
    "\n",
    "            # 1. Load & Grayscale\n",
    "            frame = cv2.imread(img_path)\n",
    "            if frame is None: continue\n",
    "            curr_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            preds = []\n",
    "            \n",
    "            # We need a previous frame to compare against\n",
    "            if prev_gray is not None:\n",
    "                # 2. Align Frames (GMC)\n",
    "                warped_prev = align_frames(prev_gray, curr_gray)\n",
    "\n",
    "                if warped_prev is not None:\n",
    "                    # 3. Difference & Threshold\n",
    "                    diff = cv2.absdiff(curr_gray, warped_prev)\n",
    "                    _, thresh = cv2.threshold(diff, 60, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "                    # 4. Clean Noise\n",
    "                    kernel = np.ones((3,3), np.uint8)\n",
    "                    thresh = cv2.dilate(thresh, kernel, iterations=2)\n",
    "                    thresh = cv2.erode(thresh, kernel, iterations=1)\n",
    "\n",
    "                    # 5. Detect Contours (Blobs)\n",
    "                    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                    \n",
    "                    for cnt in contours:\n",
    "                        area = cv2.contourArea(cnt)\n",
    "                        # Filter: Ignore tiny noise (<20) and massive alignment errors (>2000)\n",
    "                        if 100 < area < 2000: \n",
    "                            x, y, w, h = cv2.boundingRect(cnt)\n",
    "                            \n",
    "                            # 6. Border Filtering\n",
    "                            # Warping creates black bars at edges. We ignore detections there.\n",
    "                            h_img, w_img = curr_gray.shape\n",
    "                            border = 15 \n",
    "                            if x > border and y > border and (x+w) < (w_img-border) and (y+h) < (h_img-border):\n",
    "                                preds.append([x, y, w, h])\n",
    "\n",
    "            # Store current frame for next iteration\n",
    "            prev_gray = curr_gray\n",
    "\n",
    "            # 7. Evaluate vs Ground Truth\n",
    "            key = f\"{video_name}/{os.path.basename(img_path)}\"\n",
    "            gts = gt_data.get(key, [])\n",
    "            matched_gt = set()\n",
    "\n",
    "            for p_box in preds:\n",
    "                best_iou = 0\n",
    "                best_idx = -1\n",
    "                for idx, g_box in enumerate(gts):\n",
    "                    if idx in matched_gt: continue\n",
    "                    iou = calculate_iou(p_box, g_box)\n",
    "                    if iou > best_iou: best_iou = iou; best_idx = idx\n",
    "                \n",
    "                # IoU Threshold: Lower (0.20) for motion logic as shapes are imprecise\n",
    "                if best_iou >= 0.20: \n",
    "                    vid_tp += 1\n",
    "                    matched_gt.add(best_idx)\n",
    "                else:\n",
    "                    vid_fp += 1\n",
    "            \n",
    "            vid_fn += len(gts) - len(matched_gt)\n",
    "\n",
    "        # End of Video Stats\n",
    "        vid_time = time.time() - vid_start\n",
    "        fps = len(images) / vid_time if vid_time > 0 else 0\n",
    "        prec = vid_tp / (vid_tp + vid_fp) if (vid_tp + vid_fp) > 0 else 0\n",
    "        rec = vid_tp / (vid_tp + vid_fn) if (vid_tp + vid_fn) > 0 else 0\n",
    "        f1 = 2 * (prec * rec) / (prec + rec) if (prec + rec) > 0 else 0\n",
    "\n",
    "        # Clear line\n",
    "        sys.stdout.write(\"\\r\" + \" \" * 80 + \"\\r\")\n",
    "        print(f\"{video_name:<10} | {len(images):<6} | {fps:<6.1f} | {prec:<6.2f} | {rec:<6.2f} | {f1:<6.2f}\")\n",
    "\n",
    "        results_data.append({\n",
    "            'Video': video_name, 'Frames': len(images), 'FPS': round(fps, 2),\n",
    "            'Precision': round(prec, 4), 'Recall': round(rec, 4), 'F1': round(f1, 4),\n",
    "            'TP': vid_tp, 'FP': vid_fp, 'FN': vid_fn\n",
    "        })\n",
    "\n",
    "        total_time += vid_time; total_frames += len(images)\n",
    "        total_tp += vid_tp; total_fp += vid_fp; total_fn += vid_fn\n",
    "\n",
    "    # --- FINAL SUMMARY ---\n",
    "    avg_fps = total_frames / total_time if total_time > 0 else 0\n",
    "    overall_prec = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0\n",
    "    overall_rec = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0\n",
    "    overall_f1 = 2 * (overall_prec * overall_rec) / (overall_prec + overall_rec) if (overall_prec + overall_rec) > 0 else 0\n",
    "\n",
    "    print(\"=\" * 65)\n",
    "    print(\"FINAL RESULTS (GMC / Motion Compensation):\")\n",
    "    print(f\"Total Frames:   {total_frames}\")\n",
    "    print(f\"Average FPS:    {avg_fps:.2f}\")\n",
    "    print(f\"Precision:      {overall_prec:.4f}\")\n",
    "    print(f\"Recall:         {overall_rec:.4f}\")\n",
    "    print(f\"F1-Score:       {overall_f1:.4f}\")\n",
    "    print(\"=\" * 65)\n",
    "\n",
    "    df = pd.DataFrame(results_data)\n",
    "    overall_row = {\n",
    "        'Video': 'OVERALL', 'Frames': total_frames, 'FPS': round(avg_fps, 2),\n",
    "        'Precision': round(overall_prec, 4), 'Recall': round(overall_rec, 4),\n",
    "        'F1': round(overall_f1, 4), 'TP': total_tp, 'FP': total_fp, 'FN': total_fn\n",
    "    }\n",
    "    df = pd.concat([df, pd.DataFrame([overall_row])], ignore_index=True)\n",
    "    final_path = get_next_version_path(OUTPUT_CSV_PATH)\n",
    "    df.to_csv(final_path, index=False)\n",
    "    print(f\"‚úÖ CSV Saved: {final_path}\")\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"‚è±Ô∏è Process took: {elapsed_time:.2f} seconds ({elapsed_time/60:.2f} minutes)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_gmc_evaluation()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
